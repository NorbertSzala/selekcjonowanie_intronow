{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f037dd59-8d78-4bbc-b1f8-f878afe1f342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/norbert/miniconda3/lib/python3.11/site-packages/Bio/pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from Bio import AlignIO, SeqIO, Seq, pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7f5ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length_aligned_sequence = 30 #Minimal lenght of sequence which could be an exon\n",
    "extreme_homology = 0.97 #percentage of homology of sequence, treshold #I assume two faulty aligned nucleotides per 100 (98%) and one more nt because sometimes latest nt can move from end of one sequence to beginning next sequence\n",
    "middle_homology = 0.9 #used for classification of internal exons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "038e46c9-9a33-498a-a7fc-618d1fa05a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MEGA ISTOTNE PYTANIE - CO WYŚWIETLAMY????\n",
    "                    #CZY W KOLUMNIE SEQUENCE WYSWIETLAMY SEKWENCJE TRANKRYPTU CZY GENU?\n",
    "#######################################################################################\n",
    "#######################################################################################\n",
    "\n",
    "\n",
    "#cel na chwile potem:\n",
    "    #wziac pliki wyslane przez pawla i w bio pythonie je polaczyc. Jeden plik fasta zawiera po trzy scaffoldy dla kazdego gatunku oraz trzy odczyty trinity. Biopython musi je wziac ze soba i polaczyc wywalajac gapy.\n",
    "\n",
    "#pliki adama sa inaczej skonstruowane i są bardziej zawiłe: jeden plik fasta zawiera po trzy gatunki, hiemalis longa i gracilis. Kazdy z gatunkow ma tam zapisany scaffold i trinity. Olejmy to na razie i filtrowanie ich zrobimy potem\n",
    "            #chce teraz zrobic ta tabelke ktora bedzie dawala sprawnie pozycje w surowym pliku\n",
    "#moje pliki bedace inputem (te po maffcie) maja opisane jaki to organizm i jaki transrypt np EG numerki 308. Taki sam schemat jest w plikach surowych. znajdziemy czesc wspolna np. jako pierwsze x liter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6d4c5ee-799f-427e-839a-f95917b6a430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " EL_OG0030308_t2_g2_EL_PAM1_GP153_OV05 sequence is too short, sequence has not exons or other fault. \n",
      "\n",
      "                                        ID exon_or_intron_number is_it_intron  \\\n",
      "1    EG_OG0030307_t1_g1_EG_PAM1_GP153_OV05                    E1          0.0   \n",
      "2    EG_OG0030307_t1_g1_EG_PAM1_GP153_OV05                    I1          1.0   \n",
      "3    EG_OG0030307_t1_g1_EG_PAM1_GP153_OV05                    E2          0.0   \n",
      "4    EG_OG0030307_t1_g1_EG_PAM1_GP153_OV05                    I2          1.0   \n",
      "5    EG_OG0030307_t1_g1_EG_PAM1_GP153_OV05                    E3          0.0   \n",
      "..                                     ...                   ...          ...   \n",
      "144  EG_OG0030309_t3_g3_EG_PAM1_GP153_OV05                    E6          0.0   \n",
      "145  EG_OG0030309_t3_g3_EG_PAM1_GP153_OV05                    I6          1.0   \n",
      "146  EG_OG0030309_t3_g3_EG_PAM1_GP153_OV05                    E7          0.0   \n",
      "147  EG_OG0030309_t3_g3_EG_PAM1_GP153_OV05                    I7          1.0   \n",
      "148  EG_OG0030309_t3_g3_EG_PAM1_GP153_OV05                    E8          0.0   \n",
      "\n",
      "    class_of_exon  percent_of_homology_for_exons  length  first_nt_position  \\\n",
      "1               1                          97.92    96.0             2367.0   \n",
      "2            None                            NaN   102.0             2463.0   \n",
      "3               1                         100.00   145.0             2565.0   \n",
      "4            None                            NaN   238.0             2710.0   \n",
      "5               1                         100.00    72.0             2948.0   \n",
      "..            ...                            ...     ...                ...   \n",
      "144             1                          99.35   154.0             5433.0   \n",
      "145          None                            NaN   356.0             5587.0   \n",
      "146             1                         100.00    84.0             5943.0   \n",
      "147          None                            NaN  1669.0             6027.0   \n",
      "148             1                         100.00    67.0             7696.0   \n",
      "\n",
      "     last_nt_position first_10_nt  last_10_nt  \\\n",
      "1              2462.0  ctacacgtac  ggctgctcct   \n",
      "2              2564.0  gcccgccgcc  cggcgggggc   \n",
      "3              2709.0  gatcgagctg  ccgctgcttt   \n",
      "4              2947.0  gaccgggcgg  gcccgcggtc   \n",
      "5              3019.0  atgtcgccgg  caccgtggca   \n",
      "..                ...         ...         ...   \n",
      "144            5586.0  ctgagatcgt  tgattggcca   \n",
      "145            5942.0  gcgcccagtg  gtcactgcgg   \n",
      "146            6026.0  gcaattgcgg  tggattctga   \n",
      "147            7695.0  gcgccgaagt  gcgcttgcac   \n",
      "148            7762.0  gcatctgatg  tgtatgccct   \n",
      "\n",
      "                                                  path  \\\n",
      "1    /home/norbert/mrdn/euglena/kod_i_pliki/alingme...   \n",
      "2    /home/norbert/mrdn/euglena/kod_i_pliki/alingme...   \n",
      "3    /home/norbert/mrdn/euglena/kod_i_pliki/alingme...   \n",
      "4    /home/norbert/mrdn/euglena/kod_i_pliki/alingme...   \n",
      "5    /home/norbert/mrdn/euglena/kod_i_pliki/alingme...   \n",
      "..                                                 ...   \n",
      "144  /home/norbert/mrdn/euglena/kod_i_pliki/alingme...   \n",
      "145  /home/norbert/mrdn/euglena/kod_i_pliki/alingme...   \n",
      "146  /home/norbert/mrdn/euglena/kod_i_pliki/alingme...   \n",
      "147  /home/norbert/mrdn/euglena/kod_i_pliki/alingme...   \n",
      "148  /home/norbert/mrdn/euglena/kod_i_pliki/alingme...   \n",
      "\n",
      "                                              sequence  \n",
      "1    ccacaggtacaagcacgtgaacgtcatggcgccggaggtccaaagc...  \n",
      "2    gcccgccgcccggggttcggtgcccccggctgtcaggccgttgggt...  \n",
      "3    gatcgagctgctgaccggccagccggcgttccccgtctcggaggac...  \n",
      "4    gaccgggcggcctcaccatggcagtgccacatcctgggccaacaga...  \n",
      "5    atgtcgccggacgccctctcgctggccctccgctgcctcgccaagt...  \n",
      "..                                                 ...  \n",
      "144  ctgagatcgtcttccagggctgccagcagctccgcacgcagctcca...  \n",
      "145  gcgcccagtgccttgcggggcccactggcagtgctgcccaggaacc...  \n",
      "146  gcaattgcggctccatgcgcagtacgtgcggggggagagccacgcg...  \n",
      "147  gcgccgaagtgccatttgttggaacctgaggattttccttaggggt...  \n",
      "148  gcatctgatgaaggcgtccatagcaaccgccaaacggatggccctc...  \n",
      "\n",
      "[148 rows x 12 columns]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "File already exists. Do you want overwrite? y/n:  y\n"
     ]
    }
   ],
   "source": [
    "def cutting_scrap(path_to_file_after_MAFFT, path_to_file_before_MAFFT, acceptable_gap_length):\n",
    "    data_frames = []\n",
    "    gaps_signs = \"-\" * acceptable_gap_length #maximum length of gaps in sequence in one exon's sequence\n",
    "    \n",
    "    def extracting_strands_from_alignment(alignment):\n",
    "        seq1 = alignment[0].seq #transcript sequence\n",
    "        seq2 = alignment[1].seq #gene sequence\n",
    "        return seq1, seq2\n",
    "\n",
    "    #def setting_first_nucleotide_pair(alignment): #ta funkcja ucina nam 6 odczytow #to nam nie działa więc nie brnę dalej. Nie działa prawdopodobnie dlatego, że jest ona próba odwzorowania kodu, który spokojnie sobie działał w pętli while true\n",
    "        #if \"-\" in alignment[:, 0]: #deleting mismatches at the first nucleotide\n",
    "            #return alignment[:, 1:]\n",
    "        #else:\n",
    "            #return alignment\n",
    "            #print(f\"alignment after cut:\\n{alignment}\") #chekpoint\n",
    "\n",
    "\n",
    "    #def setting_last_nuckleotide_pair(alignment): #to nam nie działa więc nie brnę dalej\n",
    "        #if \"-\" in alignment[:, -1]: #deleting mismatches at the end\n",
    "            #alignment = alignment[:, :-1]\n",
    "            #return alignment \n",
    "        #else:\n",
    "            #return alignment #print(f\"alignment check:\\n{alignment[:, -50:-1]}\") checkpoint\n",
    "                    \n",
    "\n",
    "    def finding_gap_index(sequence, acceptable_gap_length):\n",
    "        return sequence.find(\"-\" * acceptable_gap_length) \n",
    "\n",
    "\n",
    "    def reversed_finding_gap_index(sequence, acceptable_gap_length):\n",
    "        return sequence.rfind(\"-\" * acceptable_gap_length) + acceptable_gap_length #now we have to add length of gap to index, because python starts counting from 0 nt, and we just change direction of counting.\n",
    "\n",
    "    def setting_distance_between_first_nt_and_gap(is_it_exon):\n",
    "        if is_it_exon == True:\n",
    "            if first_gap_position_seq2 < 0: #when in second strand there are no gaps - it means, second strand is correctly prepared\n",
    "                distance_between_first_nt_and_gap = first_gap_position_seq1\n",
    "            else:\n",
    "                distance_between_first_nt_and_gap = min(first_gap_position_seq1, first_gap_position_seq2)\n",
    "            return distance_between_first_nt_and_gap\n",
    "        elif is_it_exon == False:\n",
    "            if last_gap_position_seq2 < 0: #it means, if there is no gaps in second sequention, gap position is gap position in seq1. Additional, rfind() function return \"-1\" if it won't find any gaps in seq\n",
    "                distance_between_first_nt_and_gap = (len(seq1) - last_gap_position_seq1) -1\n",
    "                #print(\"pierwszy\", distance_between_first_nt_and_gap) #checkpoint\n",
    "            else:\n",
    "                distance_between_first_nt_and_gap = (len(seq1) - max(last_gap_position_seq1, last_gap_position_seq2))\n",
    "            return distance_between_first_nt_and_gap\n",
    "                #print(\"drugi\", distance_between_first_nt_and_gap) #checkpoint\n",
    "\n",
    "    \n",
    "    def save_to_file(final_data_frame, filename):\n",
    "        if os.path.isfile(filename):\n",
    "            user_input = input(\"File already exists. Do you want overwrite? y/n: \")\n",
    "            if user_input == \"n\":\n",
    "                base_name, ext = os.path.splitext(filename)\n",
    "                i = 1\n",
    "                while os.path.isfile(f\"{base_name}_{i}{ext}\"):\n",
    "                    i += 1\n",
    "                filename = f\"{base_name}_{i}{ext}\"\n",
    "                final_data_frame.to_csv(filename, sep = \"\\t\")\n",
    "                \n",
    "            elif user_input == \"y\":\n",
    "                final_data_frame.to_csv(filename, sep = \"\\t\")\n",
    "            else:\n",
    "                print(\"Clarify your answer. Nothing has done.\")\n",
    "                \n",
    "        else:\n",
    "            final_data_frame.to_csv(filename, sep = \"\\t\")\n",
    "            \n",
    "    \n",
    "    for filename in os.listdir(path_to_file_after_MAFFT):\n",
    "        file = os.path.join(path_to_file_after_MAFFT, filename)\n",
    "        if not os.path.isfile(file):\n",
    "            continue\n",
    "        if file.endswith(\".aln\"):\n",
    "            alignment = AlignIO.read(file, \"clustal\")\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "        #propozycje rozwiazania problemu:\n",
    "            #tu musi byc zawarta funkcja parujaca sie z zadanym plikiem alignment\n",
    "            #bierzemy nazwe pliku ktory jest obecnie zaladowany do pythona i przeszukujemy tym stringiem folder ze sciezki podanej w poszukiwaniu nazwy pliku, ktora wyglada tak: EL_OG0030308.fasta. Potem to zmienimy\n",
    "            #print(filename) jest tożsame z alignment[0].id, ale ma dodatkowe rozszerzenie .aln ktore nie stanowi problemu. Zatem obie te wersje sa zalezne od siebie, wiec potem bedzie to gorszy wybor z racji tego ze nazewnictwo zalezy ode mnie nie od programu. Chyba ze tak skontruuje program, ze on bedzie nazywal te pliki outputowe adama tak jak ja chce, wedlug mojego pomyslu nazewnictwa!\n",
    "            #print(alignment[1].id) #odrzucamy wyszukiwanie po id drugiej nici bo ona raz sie nazywa scaffold a raz backbone. \n",
    "\n",
    "\n",
    "            #czy ten fragment trzeba zamknąć do funkcji i wyeksportować ją na początek - mówie tu o kwestiach estetycznych\n",
    "            for filename_before_MAFFT in os.listdir(path_to_file_before_MAFFT):\n",
    "                file_before_MAFFT = os.path.join(path_to_file_before_MAFFT, filename_before_MAFFT)\n",
    "                if not os.path.isfile(file_before_MAFFT):\n",
    "                    #print(f\"This thingy: {str(filename_before_MAFFT)} could not be used to pair with alignment. Check it or ignore\")\n",
    "                    continue\n",
    "                if filename_before_MAFFT.endswith(\".fasta\"):\n",
    "                    #print(filename_before_MAFFT)\n",
    "                    if filename.startswith(filename_before_MAFFT[:12]):\n",
    "                        #print(f\"filename: {filename}\")\n",
    "                        max_len = 0\n",
    "                        max_genomic_seq = \"\"\n",
    "                        #przypisujemy tutaj sekwencję genomową (dłuższą) do zmiennej na której bedziemy dalej operować\n",
    "                        for record in SeqIO.parse(file_before_MAFFT, \"fasta\"):\n",
    "                            sequence = record.seq\n",
    "                            if len(sequence) > max_len:\n",
    "                                max_len = len(sequence)\n",
    "                                max_genomic_seq = record.seq   \n",
    "                         \n",
    "            while True:\n",
    "                is_it_exon = True\n",
    "                #alignment = setting_first_nucleotide_pair(alignment)\n",
    "                first_nucleotides_pair = alignment[:, 0]#first nucleotides in both strands as variable\n",
    "                if \"-\" in first_nucleotides_pair: #deleting mismatches at the start \n",
    "                    alignment = alignment[:, 1:]\n",
    "                    #print(f\"alignment after cut:\\n{alignment}\") #chekpoint\n",
    "                    continue\n",
    "    \n",
    "                \n",
    "                seq1, seq2 = extracting_strands_from_alignment(alignment)\n",
    "\n",
    "                \n",
    "                first_gap_position_seq1 = finding_gap_index(seq1, acceptable_gap_length)\n",
    "                first_gap_position_seq2 = finding_gap_index(seq2, acceptable_gap_length)\n",
    "                #print(f\"first gap position in first sequence:{first_gap_position_seq1}, in 2nd sequence: {first_gap_position_seq2}\") #checkpoint\n",
    "\n",
    "                distance_between_first_nt_and_gap = setting_distance_between_first_nt_and_gap(is_it_exon)\n",
    "                \n",
    "                local_alignment = pairwise2.align.localxx(seq1[:distance_between_first_nt_and_gap], seq2[:distance_between_first_nt_and_gap], one_alignment_only = True) #\"xx\"  means no gap penalty while opening gaps or longering them and no penalties for mismatch. Just pure score of alignment to count homology\n",
    "                #print(\"local_alignment:\", local_alignment) #checkpoint\n",
    "                   \n",
    "                try: \n",
    "                    local_homology_percentage = (local_alignment[0].score / distance_between_first_nt_and_gap) \n",
    "                except IndexError:\n",
    "                    if len(seq1) < 100:\n",
    "                        print(f\"\\n \\n {alignment[0].id} sequence is too short, sequence has not exons or other fault. \\n\")\n",
    "                        break\n",
    "                    continue\n",
    "                    \n",
    "                \n",
    "                if local_homology_percentage <= extreme_homology:\n",
    "                    #print(f\"\\n Too low score of homology. \\n alignment: {alignment[:, :50]} \\n score: {local_alignment[0].score}, distance: {distance_between_first_nt_and_gap}, percent: {round(local_homology_percentage, 2)*100}%, \\n {local_alignment}\")\n",
    "                    alignment = alignment[:, distance_between_first_nt_and_gap:] \n",
    "                    \n",
    "                else:\n",
    "                    if distance_between_first_nt_and_gap <= min_length_aligned_sequence:\n",
    "                        #print(f\"\\n alignment is too short. \\n distance between sequences {distance_between_first_nt_and_gap}, \\n alignment: {alignment}, \\n score: {local_alignment[0].score}, distance: {distance_between_first_nt_and_gap}, procentowo: {round(local_homology_percentage, 2)*100}%, \\n {local_alignment}\")\n",
    "                        alignment = alignment[:, distance_between_first_nt_and_gap:]\n",
    "                    else:\n",
    "                        #print(f\"Sequence {alignment[0].id} cut properly from LEFT side, \\n distance between sequences: {distance_between_first_nt_and_gap}\"), alignment: {alignment[:, :50]},\n",
    "                        break\n",
    "    \n",
    "               \n",
    "        \n",
    "            \n",
    "        ######################### TERAZ OD PRAWEJ DO LEWEJ #######################  \n",
    "\n",
    "    \n",
    "            \n",
    "            while True:\n",
    "                is_it_exon = False\n",
    "                last_nucleotides_pair = alignment[:, -1]#last nucleotides in both strands as variable\n",
    "                if \"-\" in last_nucleotides_pair: #deleting mismatches at the end\n",
    "                    alignment = alignment[:, :-1]\n",
    "                     #print(f\"alignment check:\\n{alignment[:, -50:-1]}\") checkpoint\n",
    "                    continue\n",
    "                             \n",
    "                seq1, seq2 = extracting_strands_from_alignment(alignment)\n",
    "\n",
    "                last_gap_position_seq1 = reversed_finding_gap_index(seq1, acceptable_gap_length)\n",
    "                last_gap_position_seq2 = reversed_finding_gap_index(seq2, acceptable_gap_length)\n",
    "                #print(\"seq1:\", last_gap_position_seq1, \"seq2:\", last_gap_position_seq2) #checkpoint\n",
    "                \n",
    "                distance_between_first_nt_and_gap = setting_distance_between_first_nt_and_gap(is_it_exon)\n",
    "                #print(\"drugi\", distance_between_first_nt_and_gap)\n",
    "                        \n",
    "                local_alignment = pairwise2.align.localxx(seq1[-distance_between_first_nt_and_gap:], seq2[-distance_between_first_nt_and_gap:], one_alignment_only = True) #\"xx\" means no gap penalty while opening gaps or longering them and no penalties for mismatch. Just pure score of alignment\n",
    "                #print(\"local_alignment:\", local_alignment) #checkpoint\n",
    "                \n",
    "                \n",
    "        \n",
    "                try:\n",
    "                    if distance_between_first_nt_and_gap != 0:\n",
    "                        local_homology_percentage = (local_alignment[0].score / distance_between_first_nt_and_gap) \n",
    "                    else:\n",
    "                        break\n",
    "                except IndexError:\n",
    "                    if len(seq1) < 100:\n",
    "                        print(f\"\\n \\n {alignment[0].id} sequence is too short or sequence has not exons. \\n\")\n",
    "                        break\n",
    "                    continue\n",
    "        \n",
    "                \n",
    "                if local_homology_percentage <= extreme_homology:\n",
    "                     #print(f\"\\n Too low homology! \\n alignment: {alignment[:, -50:]} \\n score: {local_alignment[0].score}, \\distance: {distance_between_first_nt_and_gap}, %%%: {round(local_homology_percentage, 2)*100}%, \\n {local_alignment}\")\n",
    "                    alignment = alignment[:, :-distance_between_first_nt_and_gap] \n",
    "                    \n",
    "                else:\n",
    "                    if distance_between_first_nt_and_gap <= min_length_aligned_sequence:\n",
    "                        #print(f\"\\n Alignment is too short!. \\n distance: {distance_between_first_nt_and_gap}, \\n alignment: {alignment}, \\n score: {local_alignment[0].score}, distance: {distance_between_first_nt_and_gap}, %%%: {round(local_homology_percentage, 2)*100}%, \\n {local_alignment}\")\n",
    "                        alignment = alignment[:, :-distance_between_first_nt_and_gap]\n",
    "                    else:\n",
    "                        #print(f\"Sequence: {alignment[0].id} cut properly from RIGHT side, alignment: \\n {alignment[:, -50:]}\")\n",
    "                        break\n",
    "\n",
    "        \n",
    "        \n",
    "            \n",
    "            nucleotides = [\"a\", \"t\", \"g\", \"c\", \"A\", \"T\", \"G\", \"C\"]\n",
    "            index = 0\n",
    "            \n",
    "            id = []\n",
    "            exon_or_intron_number = []\n",
    "            is_it_intron = []\n",
    "            class_of_exon = []\n",
    "            percent_of_homology_for_exons = []\n",
    "            length = []\n",
    "            first_nt_position = []\n",
    "            last_nt_position = []\n",
    "            first_10_nt = []\n",
    "            last_10_nt = []\n",
    "            path = []\n",
    "            sequence = []\n",
    "\n",
    "            \n",
    "            while True:\n",
    "                try: \n",
    "                    if distance_between_first_nt_and_gap != 0:\n",
    "                        local_homology_percentage = (local_alignment[0].score / distance_between_first_nt_and_gap) #that sign \"[]\" becouse local_alignment's type is list\n",
    "                    else:\n",
    "                        break\n",
    "                except IndexError:\n",
    "                    if len(seq1) < 100:\n",
    "                        print(f\"\\n \\n {alignment[0].id} sequence is too short or sequence has not exons. \\n\")\n",
    "                        break\n",
    "                    continue\n",
    "                \n",
    "                if len(seq1) > 1 and seq1[0] != gaps_signs:#mining data from exons\n",
    "                    index += 1\n",
    "                    last_nt_exon_index = seq1.find(gaps_signs) \n",
    "                \n",
    "                    if last_nt_exon_index == -1: #it means if it is last exon, if find() don't find any gap signs at the end\n",
    "                        last_nt_exon_index = len(seq1)\n",
    "                                \n",
    "                    alignment_of_exon = pairwise2.align.localxx(seq1[:last_nt_exon_index], seq2[:last_nt_exon_index], one_alignment_only = True)\n",
    "                        #print( \"\\n alignment since start to the end of exon:\", alignment_of_exon[0])\n",
    "                    percent_of_homology = alignment_of_exon[0].score / last_nt_exon_index\n",
    "                        #print(\"exon analising finished\")\n",
    "                            \n",
    "            \n",
    "                    #extending lists to make bigger dictionary and then data frame\n",
    "                    id.append(alignment[0].id)\n",
    "                    exon_or_intron_number.append(f\"E{index}\")\n",
    "                    is_it_intron.append(False)\n",
    "                    percent_of_homology_for_exons.append(round(percent_of_homology * 100, 2))\n",
    "                    length.append(last_nt_exon_index)\n",
    "                    first_10_nt.append(str(seq1[:10]))\n",
    "                    last_10_nt.append(str(seq2[last_nt_exon_index-10 : last_nt_exon_index])) \n",
    "                    sequence.append(str(seq2[:last_nt_exon_index]).replace(\"-\", \"\"))\n",
    "                    path.append(str(file))\n",
    "\n",
    "\n",
    "                    #adding indices of start and end of exons\n",
    "                    first_nt_index_of_exon = max_genomic_seq.find(str(seq2[:last_nt_exon_index]).replace(\"-\", \"\"))\n",
    "                    if first_nt_index_of_exon == -1:\n",
    "                        first_nt_position.append(0)\n",
    "                        print(f\"That exon: {str(seq2[:last_nt_exon_index]).replace('-', '')} comes from genomic sequence and cannot be found in file_before_MAFFT.\")\n",
    "\n",
    "                    else:\n",
    "                        first_nt_position.append(first_nt_index_of_exon+1)\n",
    "\n",
    "                    if first_nt_index_of_exon == -1:\n",
    "                        last_nt_position.append(0)\n",
    "                    else:\n",
    "                        last_nt_position.append(first_nt_index_of_exon + len(seq2[:last_nt_exon_index]))\n",
    "                    \n",
    "                    #describing class of exon\n",
    "                    if percent_of_homology >= 0.9 and last_nt_exon_index >= min_length_aligned_sequence :\n",
    "                        class_of_exon.append(\"1\")\n",
    "                    elif percent_of_homology < 0.9 and percent_of_homology > 0 and last_nt_exon_index < min_length_aligned_sequence:\n",
    "                        class_of_exon.append(\"2\")\n",
    "                    else:\n",
    "                        class_of_exon.append(\"3\")\n",
    "            \n",
    "                    seq1 = seq1[last_nt_exon_index:]\n",
    "                    seq2 = seq2[last_nt_exon_index:]\n",
    "                    #print(\"analising exon finished\") #checkpoint\n",
    "                            \n",
    "                #expanding index\n",
    "                if len(seq1) > 1 and seq1[0] == \"-\":\n",
    "                    for i, nukleotide in enumerate(seq1):\n",
    "                        if nukleotide not in nucleotides:\n",
    "                            last_nt_intron_index = i+1\n",
    "                        else:\n",
    "                            break\n",
    "\n",
    "                    #extending lists to make bigger dictionary and then data frame\n",
    "                    id.append(alignment[0].id)\n",
    "                    exon_or_intron_number.append(f\"I{index}\")\n",
    "                    is_it_intron.append(True)\n",
    "                    class_of_exon.append(None)\n",
    "                    percent_of_homology_for_exons.append(None)\n",
    "                    length.append(last_nt_intron_index)\n",
    "                    #first_nt_position.append(0)\n",
    "                    #last_nt_position.append(0)\n",
    "                    first_10_nt.append(str(seq2[:10]))\n",
    "                    last_10_nt.append(str(seq2[last_nt_intron_index-10 : last_nt_intron_index]))\n",
    "                    sequence.append(str(seq2[:last_nt_intron_index]).replace(\"-\", \"\"))\n",
    "                    path.append(str(file))\n",
    "\n",
    "                    \n",
    "                    first_nt_index_of_intron = max_genomic_seq.find(str(seq2[:last_nt_intron_index]))\n",
    "                    if first_nt_index_of_intron == -1:\n",
    "                        first_nt_position.append(0)\n",
    "                    else:\n",
    "                        #print(first_nt_index_of_intron)\n",
    "                        first_nt_position.append(first_nt_index_of_intron+1)\n",
    "\n",
    "                    if first_nt_index_of_intron == -1:\n",
    "                        last_nt_position.append(0)\n",
    "                    else:\n",
    "                        last_nt_position.append(first_nt_index_of_intron + len(seq2[:last_nt_intron_index]))\n",
    "\n",
    "                    #tutaj damy liste ktorej inputem bedzie ostatni element listy z exonow, do ktorego dodamy dlugosc tego eksonu +1 zeby znalezc poczatkowy index intronu\n",
    "                    seq1 = seq1[last_nt_intron_index:]\n",
    "                    seq2 = seq2[last_nt_intron_index:]\n",
    "                    \n",
    "                else:\n",
    "                     break\n",
    "                        \n",
    "            dictionary = {\"ID\":id,\n",
    "                          \"exon_or_intron_number\":exon_or_intron_number, \n",
    "                          \"is_it_intron\":is_it_intron, \n",
    "                          \"class_of_exon\":class_of_exon, \n",
    "                          \"percent_of_homology_for_exons\":percent_of_homology_for_exons, \n",
    "                          \"length\":length,\n",
    "                          \"first_nt_position\" : first_nt_position,\n",
    "                          \"last_nt_position\" : last_nt_position,\n",
    "                          \"first_10_nt\" : first_10_nt,\n",
    "                          \"last_10_nt\" : last_10_nt, \n",
    "                          \"path\":path, \n",
    "                          \"sequence\" : sequence}\n",
    "            data_frame = pd.DataFrame(dictionary)\n",
    "            #print(data_frame)\n",
    "        data_frames.append(data_frame)\n",
    "        #print(data_frames)\n",
    "\n",
    "\n",
    "    final_data_frame = pd.concat(data_frames, ignore_index=True)\n",
    "    final_data_frame.index = np.arange(1, len(final_data_frame) + 1)\n",
    "    print(final_data_frame)\n",
    "    \n",
    "    save_to_file(final_data_frame, \"przyciete_introny.tsv\")\n",
    "\n",
    "\n",
    "cutting_scrap('/home/norbert/mrdn/euglena/kod_i_pliki/alingment_gen_transkrypt/', \"/home/norbert/mrdn/euglena/kod_i_pliki/surowe_pliki_plus_minus_500\", 2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a04e46-1593-4d3e-9423-54efbcfe4bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

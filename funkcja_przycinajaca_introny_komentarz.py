{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f037dd59-8d78-4bbc-b1f8-f878afe1f342",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Bio import AlignIO, SeqIO, Seq, pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daa9c022-9b97-48b7-b7f7-9d01e024710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ASSUMPTIONS\n",
    "#- both file, path_to_file_before_MAFFT and path_to_file_after_MAFFT have to have the same name\n",
    "#- they have to be .fasta\n",
    "\n",
    "\n",
    "min_length_aligned_sequence = 30 #Minimal lenght of sequence which could be an exon\n",
    "extreme_homology = 0.97 #percentage of homology of sequence, treshold #I assume two faulty aligned nucleotides per 100 (98%) and one more nt because sometimes latest nt can move from end of one sequence to beginning next sequence\n",
    "\n",
    "\n",
    "path_to_file_before_MAFFT = \"/home/norbert/mrdn/euglena/kod_i_pliki/surowe_pliki_plus_minus_500/raw_reads_9/merging_fastas\"\n",
    "path_to_file_after_MAFFT = \"/home/norbert/mrdn/euglena/kod_i_pliki/surowe_pliki_plus_minus_500/raw_reads_9/fastas_after_mafft_na_probe\"\n",
    "\n",
    "#DODAJ FRAGMENT MOWIACY ZE JESLI: NA RAZIE SIE WSTRZYMAM, MOZE NIE JEST TO POTRZEBNE\n",
    "    #LICZBA INTRONOW >= LICZBIE EKSONOW TO BREAK\n",
    "    #LICZBA INTRONOW + EKSONOW <= 3 TO BREAK\n",
    "\n",
    "\n",
    "#dodac tabelke tak by mowila ile bylo odczytow na inpucie, ile przeszło pozytywnie a ile zostało przerwanych w trakcie\n",
    "#dodatkowa tabelka ze wszystkimi eksonami które byly za krótkie też\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42d489c2-e090-4244-98db-a453e82cc84b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running file: LON_OG0030309.fasta which is 1 of 9, what means 11.11% of advancement \n",
      "0.53% base pair done of LON_SL+_GGOE01000359.1. 1 of 9, what means 11.11% of advancement. The time is: 23:05:07\n",
      "First 50 nt of reference sequence is: agatatgacaggctggcctttgtttgtgttgttttgtgaaacgaagaagt. \n",
      "\n",
      "2.08% base pair done of LON_SL+_GGOE01000359.1. 1 of 9, what means 11.11% of advancement. The time is: 23:05:07\n",
      "First 50 nt of reference sequence is: tattttttaagttggccatctgcatccacttgttagcaattggtttgctt. \n",
      "\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'last_gap_position_seq1' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 511\u001b[0m\n\u001b[1;32m    508\u001b[0m         gff_final_data_frame\u001b[38;5;241m.\u001b[39mto_csv(filename, sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 511\u001b[0m     \u001b[43mcutting_scrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_file_before_MAFFT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_to_file_after_MAFFT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 64\u001b[0m, in \u001b[0;36mcutting_scrap\u001b[0;34m(path_to_file_before_MAFFT, path_to_file_after_MAFFT, acceptable_gap_length)\u001b[0m\n\u001b[1;32m     61\u001b[0m first_gap_position_seq2 \u001b[38;5;241m=\u001b[39m finding_gap_index(seq2, acceptable_gap_length)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#print(f\"first gap position in first sequence:{first_gap_position_seq1}, in 2nd sequence: {first_gap_position_seq2}\") #checkpoint\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m distance_between_first_nt_and_gap \u001b[38;5;241m=\u001b[39m setting_distance_between_first_nt_and_gap(is_it_exon, seq1, first_gap_position_seq1, first_gap_position_seq2, \u001b[43mlast_gap_position_seq1\u001b[49m, last_gap_position_seq2)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m#tutaj mozemy cos wstawić!\u001b[39;00m\n\u001b[1;32m     67\u001b[0m local_alignment \u001b[38;5;241m=\u001b[39m pairwise2\u001b[38;5;241m.\u001b[39malign\u001b[38;5;241m.\u001b[39mlocalxx(seq1[:distance_between_first_nt_and_gap], seq2[:distance_between_first_nt_and_gap], one_alignment_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#\"xx\"  means no gap penalty while opening gaps or longering them and no penalties for mismatch. Just pure score of alignment to count homology\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'last_gap_position_seq1' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "#funkcja setting_distance_between_first_nt_and_gap pobiera zmienną last_gap_position_seq1 zanim ta została określona w następnej funkcji\n",
    "def cutting_scrap(path_to_file_before_MAFFT, path_to_file_after_MAFFT, acceptable_gap_length):\n",
    "    data_frames = []\n",
    "    gff_data_frames = []\n",
    "    gaps_signs = \"-\" * acceptable_gap_length #maximum length of gaps in sequence in one exon's sequence\n",
    "    files_in_progress = 0\n",
    "    #print(f\"\\n \\n \\n \\n Just run function: cutting_scrap\")\n",
    "\n",
    "\n",
    "    for filename in os.listdir(path_to_file_after_MAFFT):\n",
    "        #print(\"Just tried make 1st turn - find all filenames, \\n there is filename: \", str(filename))\n",
    "        file = os.path.join(path_to_file_after_MAFFT, filename)\n",
    "        if not os.path.isfile(file):\n",
    "            continue\n",
    "        if file.endswith(\".fasta\"):\n",
    "            files_in_progress += 1\n",
    "            count_files = percentage_of_advancement(path_to_file_before_MAFFT)\n",
    "            print(f\"running file: {filename} which is {files_in_progress} of {count_files}, what means {round(files_in_progress/count_files*100, 2)}% of advancement \")\n",
    "            alignment = AlignIO.read(file, \"fasta\")\n",
    "            alignment_DIDNT_TOUCHED = AlignIO.read(file, \"fasta\")\n",
    "            #print(f\"NA POCZATKU alignment: {alignment[0].id} ma dlugosc {len(alignment[0])}\")\n",
    "\n",
    "        count_of_errors = 0\n",
    "        for filename in os.listdir(path_to_file_before_MAFFT):\n",
    "            file_before_MAFFT = os.path.join(path_to_file_before_MAFFT, filename)\n",
    "            if not os.path.isfile(file_before_MAFFT):\n",
    "                break\n",
    "            else:\n",
    "                if len(alignment[0].id) >= len(alignment[1].id):\n",
    "                    max_genomic_seq = alignment[0].seq\n",
    "                else:\n",
    "                    max_genomic_seq = alignment[1].seq\n",
    "                \n",
    "            \n",
    "\n",
    "            while True:\n",
    "\t\t\t\t\t\n",
    "                is_it_exon = True\n",
    "                #alignment = setting_first_nucleotide_pair(alignment) #function that doesn't work\n",
    "                first_nucleotides_pair = alignment[:, 0]#first nucleotides in both strands as variable\n",
    "                if \"-\" in first_nucleotides_pair: #deleting mismatches at the start\n",
    "                    if len(alignment[0]) % 100 == 0:\n",
    "                        print(f\"{round((100-(len(alignment[0])/len(alignment_DIDNT_TOUCHED[0]))*100), 2)}% base pair done of {alignment[0].id}. {files_in_progress} of {count_files}, what means {round(files_in_progress/count_files*100, 2)}% of advancement. The time is: {time.strftime('%H:%M:%S', time.localtime())}\")\n",
    "                        print(f\"First 50 nt of reference sequence is: {(alignment[1].seq)[:50]}. \\n\")\n",
    "                    if len(alignment[0]) < 100: #zakoczenie przycinania - nie wiem czy to jest to o co mi chodzilo\n",
    "                        break\n",
    "                    else:\n",
    "                        alignment = alignment[:, 1:]\n",
    "                        #print(f\"alignment after cut:\\n{alignment}\") #chekpoint\n",
    "                    continue\n",
    "\n",
    "    \n",
    "                \n",
    "                seq1, seq2 = extracting_strands_from_alignment(alignment)\n",
    "\n",
    "                seq1_DT, seq2_DT = extracting_strands_from_alignment(alignment_DIDNT_TOUCHED) #sequences without cutted gaps from the ends. They will be used to count index where intron starts\n",
    "                \n",
    "                if len(seq1) < 100 or len(seq2) < 100:\n",
    "                    break\n",
    "\n",
    "                first_gap_position_seq1 = finding_gap_index(seq1, acceptable_gap_length)\n",
    "                first_gap_position_seq2 = finding_gap_index(seq2, acceptable_gap_length)\n",
    "                #print(f\"first gap position in first sequence:{first_gap_position_seq1}, in 2nd sequence: {first_gap_position_seq2}\") #checkpoint\n",
    "                \n",
    "                distance_between_first_nt_and_gap = setting_distance_between_first_nt_and_gap(is_it_exon, seq1, first_gap_position_seq1, first_gap_position_seq2, last_gap_position_seq1, last_gap_position_seq2)\n",
    "                \n",
    "                \n",
    "                local_alignment = pairwise2.align.localxx(seq1[:distance_between_first_nt_and_gap], seq2[:distance_between_first_nt_and_gap], one_alignment_only = True) #\"xx\"  means no gap penalty while opening gaps or longering them and no penalties for mismatch. Just pure score of alignment to count homology\n",
    "                #print(\"local_alignment:\", local_alignment) #checkpoint\n",
    "\n",
    "                try:  #instruction what to do when seq is too short\n",
    "                    local_homology_percentage = (local_alignment[0].score / distance_between_first_nt_and_gap) \n",
    "                except IndexError:\n",
    "                    if len(seq1) < 100:\n",
    "                        count_of_errors += 1\n",
    "                        print(f\"That file {filename} made {count_of_errors}th error\")\n",
    "                        #print(f\"\\n \\n {alignment[0].id} sequence is too short, sequence has not exons or other fault. \\n\")\n",
    "                        break\n",
    "                    continue\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                if local_homology_percentage <= extreme_homology:\n",
    "                    #print(f\" Too low score of homology. \\n alignment: {alignment[:, :50]} \\n score: {local_alignment[0].score}, distance: {distance_between_first_nt_and_gap}, percent: {round(local_homology_percentage, 2)*100}%, \\n {local_alignment} \\n \\n \\n \\n \\n\")\n",
    "                    alignment = alignment[:, distance_between_first_nt_and_gap:] \n",
    "                    \n",
    "                else:\n",
    "                    if distance_between_first_nt_and_gap <= min_length_aligned_sequence:\n",
    "                        #print(f\"\\n alignment is too short. \\n distance between sequences {distance_between_first_nt_and_gap}, \\n alignment: {alignment}, \\n score: {local_alignment[0].score}, distance: {distance_between_first_nt_and_gap}, procentowo: {round(local_homology_percentage, 2)*100}%, \\n {local_alignment}\")\n",
    "                        alignment = alignment[:, distance_between_first_nt_and_gap:]\n",
    "                    else:\n",
    "                        #print(f\"Sequence {alignment[0].id} cut properly from LEFT side, \\n distance between sequences: {distance_between_first_nt_and_gap}\"), alignment: {alignment[:, :50]},\n",
    "                        break\n",
    "                        \n",
    "                if len(seq1) < 100 or len(seq2) < 100:\n",
    "                    break\n",
    "            \n",
    "        ######################### TERAZ OD PRAWEJ DO LEWEJ #######################\n",
    "            \n",
    "            while True:\n",
    "                    \n",
    "                is_it_exon = False\n",
    "                last_nucleotides_pair = alignment[:, -1]#last nucleotides in both strands as variable\n",
    "\n",
    "                if \"-\" in last_nucleotides_pair: #deleting mismatches at the end\n",
    "                    if len(alignment[0]) < 100 or len(alignment[1]) < 100:\n",
    "                        #print(\"alignment has no matching nucleotides\")\n",
    "                        break \n",
    "                    else:\n",
    "                        alignment = alignment[:, :-1]\n",
    "                        #print(f\"alignment check:\\n{alignment[:, -50:-1]}\") checkpoint\n",
    "                    continue\n",
    "                else:\n",
    "                    if len(alignment[0]) < 100 or len(alignment[1]) < 0:\n",
    "                        #print(\"counting from right side: alignment is too short\")\n",
    "                        break\n",
    "                \n",
    "\n",
    "                    \n",
    "            \n",
    "                seq1, seq2 = extracting_strands_from_alignment(alignment)\n",
    "                \n",
    "                if len(seq1) < 100 or len(seq2) < 100:\n",
    "                    #print(\"that alignment: \", alignment, \"is too short\")\n",
    "                    break\n",
    "\t\t\t\t\t\n",
    "                last_gap_position_seq1 = reversed_finding_gap_index(seq1, acceptable_gap_length)\n",
    "                last_gap_position_seq2 = reversed_finding_gap_index(seq2, acceptable_gap_length)\n",
    "                #print(\"seq1:\", last_gap_position_seq1, \"seq2:\", last_gap_position_seq2) #checkpoint\n",
    "                \n",
    "                distance_between_first_nt_and_gap = setting_distance_between_first_nt_and_gap(is_it_exon, seq1, first_gap_position_seq1, first_gap_position_seq2, last_gap_position_seq1, last_gap_position_seq2)\n",
    "                #print(\"drugi\", distance_between_first_nt_and_gap)\n",
    "                        \n",
    "                local_alignment = pairwise2.align.localxx(seq1[-distance_between_first_nt_and_gap:], seq2[-distance_between_first_nt_and_gap:], one_alignment_only = True) #\"xx\" means no gap penalty while opening gaps or longering them and no penalties for mismatch. Just pure score of alignment\n",
    "                #print(\"local_alignment:\", local_alignment) #checkpoint\n",
    "                \n",
    "                \n",
    "        \n",
    "                try:#instruction what to do when seq is too short or gaps were not found\n",
    "                    if distance_between_first_nt_and_gap != 0:\n",
    "                        local_homology_percentage = (local_alignment[0].score / distance_between_first_nt_and_gap) \n",
    "                    else:\n",
    "                        break\n",
    "                except IndexError:\n",
    "                    if len(seq1) < 100:\n",
    "                        count_of_errors += 1\n",
    "                        print(f\"That file {filename} made {count_of_errors}th error\")\n",
    "                        #print(f\"\\n \\n {alignment[0].id} sequence is too short or sequence has not exons. \\n\")\n",
    "                        break\n",
    "                    continue\n",
    "        \n",
    "                \n",
    "                if local_homology_percentage <= extreme_homology:\n",
    "                    #print(f\"\\n Too low homology! \\n alignment: {alignment[:, -50:]} \\n score: {local_alignment[0].score}, \\distance: {distance_between_first_nt_and_gap}, %%%: {round(local_homology_percentage, 2)*100}%, \\n {local_alignment}\")\n",
    "                    alignment = alignment[:, :-distance_between_first_nt_and_gap] \n",
    "                    \n",
    "                else:\n",
    "                    if distance_between_first_nt_and_gap <= min_length_aligned_sequence:\n",
    "                        #print(f\"\\n Alignment is too short!. \\n distance: {distance_between_first_nt_and_gap}, \\n alignment: {alignment}, \\n score: {local_alignment[0].score}, distance: {distance_between_first_nt_and_gap}, %%%: {round(local_homology_percentage, 2)*100}%, \\n {local_alignment}\")\n",
    "                        alignment = alignment[:, :-distance_between_first_nt_and_gap]\n",
    "                    else:\n",
    "                        #print(f\"Sequence: {alignment[0].id} cut properly from RIGHT side, alignment: \\n {alignment[:, -50:]}\")\n",
    "                        break\n",
    "                        \n",
    "                if len(seq1) < 100 or len(seq2) < 100:\n",
    "                    break\n",
    "        \n",
    "        \n",
    "            \n",
    "            nucleotides = [\"a\", \"t\", \"g\", \"c\", \"A\", \"T\", \"G\", \"C\"]\n",
    "            index = 0\n",
    "\n",
    "            #do tsv\n",
    "            id = []\n",
    "            exon_or_intron_number = []\n",
    "            is_it_intron = []\n",
    "            class_of_exon = []\n",
    "            percent_of_homology_for_exons = []\n",
    "            length = []\n",
    "            first_nt_position = []\n",
    "            last_nt_position = []\n",
    "            first_10_nt = []\n",
    "            last_10_nt = []\n",
    "            path = []\n",
    "            sequence = []\n",
    "\n",
    "            #do gff\n",
    "            seqid = [] #name of the chromosome or scaffold; chromosome names can be given with or without the 'chr' prefix. Important note: the seq ID must be one used within Ensembl, i.e. a standard chromosome name or an Ensembl identifier such as a scaffold ID, without any additional content such as species or assembly. See the example GFF output below.\n",
    "            source = [] #tutaj pominiemy ten krok - damy kropke #Describes the algorithm or the procedure that generated this feature. Typically Genescane or Genebank, respectively. #scaffold backbone trinity  i te numerki jakieś\n",
    "            type = [] #Describes what the feature is (mRNA, domain, exon, etc.). #scaffold backbone trinity  i te numerki jakieś #intron lub exon\n",
    "            start = []\n",
    "            end = []\n",
    "            score = [] #Typically E-values for sequence similarity and P-values for predictions. Homology there\n",
    "            strand = []\n",
    "            phase = [] #Indicates where the feature begins with reference to the reading frame. The phase is one of the integers 0, 1, or 2, indicating the number of bases that should be removed from the beginning of this feature to reach the first base of the next codon.. Propably 0\n",
    "            attributes = [] #A semicolon-separated list of tag-value pairs, providing additional information about each feature. Some of these tags are predefined, e.g. ID, Name, Alias, Parent . You can see the full list [here](https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md).\n",
    "\n",
    "            \n",
    "            while True: #instruction what to do when seq is too short or gaps were not found\n",
    "                try: \n",
    "                    if distance_between_first_nt_and_gap != 0:\n",
    "                        local_homology_percentage = (local_alignment[0].score / distance_between_first_nt_and_gap) #that sign \"[]\" becouse local_alignment's type is list\n",
    "                    else:\n",
    "                        break\n",
    "                except IndexError:\n",
    "                    if len(seq1) < 100:\n",
    "                        count_of_errors += 1\n",
    "                        print(f\"That file {filename} made {count_of_errors}th error\")\n",
    "                        #print(f\"\\n \\n {alignment[0].id} sequence is too short or sequence has not exons. \\n\")\n",
    "                        break\n",
    "                    continue\n",
    "\n",
    "                if len(seq1) > 1 and seq1[0] != gaps_signs:#mining data from exons\n",
    "                    is_it_exon = True\n",
    "                    index += 1\n",
    "                    last_nt_exon_index = seq1.find(gaps_signs) \n",
    "                \n",
    "                    if last_nt_exon_index == -1: #it means if it is last exon, if find() don't find any gap signs at the end\n",
    "                        last_nt_exon_index = len( seq1)\n",
    "                                \n",
    "                    alignment_of_exon = pairwise2.align.localxx(seq1[:last_nt_exon_index], seq2[:last_nt_exon_index], one_alignment_only = True)\n",
    "                    #print( \"\\n alignment since start to the end of exon:\", alignment_of_exon[0])\n",
    "                    percent_of_homology = alignment_of_exon[0].score / last_nt_exon_index\n",
    "                    #print(\"exon analising finished\")\n",
    "                            \n",
    "                    \n",
    "                    #extending lists to make bigger dictionary and then data frame\n",
    "                    #tsv data frame\n",
    "                    id.append(alignment[0].id)\n",
    "                    exon_or_intron_number.append(f\"E{index}\")\n",
    "                    is_it_intron.append(False)\n",
    "                    percent_of_homology_for_exons.append(round(percent_of_homology * 100, 2))\n",
    "                    length.append(last_nt_exon_index)\n",
    "                    first_10_nt.append(str(seq1[:10]))\n",
    "                    last_10_nt.append(str(seq2[last_nt_exon_index-10 : last_nt_exon_index])) \n",
    "                    sequence.append(str(seq2[:last_nt_exon_index]).replace(\"-\", \"\"))\n",
    "                    path.append(str(file))\n",
    "                    exons_indices(is_it_exon, max_genomic_seq, seq2, last_nt_exon_index, last_nt_position, first_nt_position)\n",
    "                    describing_class_of_exon(percent_of_homology, last_nt_exon_index, min_length_aligned_sequence, class_of_exon)\n",
    "\n",
    "                    \n",
    "                    #gff data frame\n",
    "                    seqid.append(alignment[0].id)\n",
    "                    extending_source_data_frame(alignment, source)  #czyli  backbone czy trinity czy scaffold \n",
    "                    type.append(\"exon\")\n",
    "                    #extending_start_exon_data_frame(seq2, seq2_DT)  #exon intron  #numer nukleotydu w pliku wejściowym w sekwencji genomowej\n",
    "                    #extending_end_exon_data_frame(seq2, seq2_DT) #numer nukleotydu w pliku wejściowym w sekwencji genomowej\n",
    "                    extending_start_and_end_data_frame(is_it_exon, seq2, seq2_DT, start, end, distance_between_first_nt_and_gap, last_nt_exon_index)\n",
    "                    score.append(round(percent_of_homology * 100, 2)) # pokrycie - bez znaczenia\n",
    "                    extending_strand_data_frame(alignment, strand)  #plus czy minus  z nazwy sekwencji\n",
    "                    phase.append(\".\") #???\n",
    "                    attributes.append(alignment[0].id) #cala reszta\n",
    "\n",
    "\n",
    "                    \n",
    "                    seq1 = seq1[last_nt_exon_index:]\n",
    "                    seq2 = seq2[last_nt_exon_index:]\n",
    "                    #print(\"analising exon finished\") #checkpoint\n",
    "                            \n",
    "                #expanding index\n",
    "                if len(seq1) > 1 and seq1[0] == \"-\":\n",
    "                    is_is_exon = False\n",
    "                    for i, nukleotide in enumerate(seq1):\n",
    "                        if nukleotide not in nucleotides:\n",
    "                            last_nt_intron_index = i+1\n",
    "                        else:\n",
    "                            break\n",
    "\n",
    "                    #extending lists to make bigger dictionary and then data frame\n",
    "                    id.append(alignment[0].id)\n",
    "                    exon_or_intron_number.append(f\"I{index}\")\n",
    "                    is_it_intron.append(True)\n",
    "                    class_of_exon.append(None)\n",
    "                    percent_of_homology_for_exons.append(None)\n",
    "                    length.append(last_nt_intron_index)\n",
    "                    first_10_nt.append(str(seq2[:10]))\n",
    "                    last_10_nt.append(str(seq2[last_nt_intron_index-10 : last_nt_intron_index]))\n",
    "                    sequence.append(str(seq2[:last_nt_intron_index]).replace(\"-\", \"\"))\n",
    "                    path.append(str(file))\n",
    "                    introns_indices(is_it_exon, max_genomic_seq, seq2, last_nt_intron_index, first_nt_position, last_nt_position)\n",
    "\n",
    "\n",
    "                    #gff data frame\n",
    "                    seqid.append(alignment[0].id)\n",
    "                    extending_source_data_frame(alignment, source)  #czyli  backbone czy trinity czy scaffold. U nas wszedzie trinity\n",
    "                    type.append(\"intron\") #exon intron\n",
    "                    extending_start_and_end_data_frame(is_it_exon, seq2, seq2_DT, start, end, distance_between_first_nt_and_gap, last_nt_exon_index)\n",
    "                    score.append(None) # pokrycie - bez znaczenia\n",
    "                    extending_strand_data_frame(alignment, strand)  #plus czy minus  z nazwy sekwencji\n",
    "                    phase.append(\".\") #???\n",
    "                    attributes.append(alignment[0].id) #cala reszta\n",
    "\n",
    "                    \n",
    "                    seq1 = seq1[last_nt_intron_index:]\n",
    "                    seq2 = seq2[last_nt_intron_index:]\n",
    "                    \n",
    "                else:\n",
    "                     break\n",
    "                        \n",
    "            dictionary = {\"ID\":id,\n",
    "                          \"exon_or_intron_number\":exon_or_intron_number, \n",
    "                          \"is_it_intron\":is_it_intron, \n",
    "                          \"class_of_exon\":class_of_exon, \n",
    "                          \"percent_of_homology_for_exons\":percent_of_homology_for_exons, \n",
    "                          \"length\":length,\n",
    "                          \"first_nt_position\" : first_nt_position,\n",
    "                          \"last_nt_position\" : last_nt_position,\n",
    "                          \"first_10_nt\" : first_10_nt,\n",
    "                          \"last_10_nt\" : last_10_nt, \n",
    "                          \"path\":path, \n",
    "                          \"sequence\" : sequence}\n",
    "\n",
    "            gff_dictionary = {\"seqid\":seqid,\n",
    "                             \"source\":source,\n",
    "                             \"type\":type,\n",
    "                             \"start\":start,\n",
    "                             \"end\":end,\n",
    "                             \"score\":score,\n",
    "                              \n",
    "                             \"strand\":strand,\n",
    "                             \"phase\":phase,\n",
    "                             \"attributes\":attributes}\n",
    "\n",
    "            data_frame = pd.DataFrame(dictionary)                   \n",
    "            gff_data_frame = pd.DataFrame(gff_dictionary)\n",
    "            #print(data_frame)\n",
    "        data_frames.append(data_frame)\n",
    "        gff_data_frames.append(gff_data_frame)\n",
    "        #print(f\"NA KONCU alignment: {alignment[0].id} ma dlugosc {len(alignment[0])}\")\n",
    "        #print(gff_data_frames)\n",
    "\n",
    "    \n",
    "    final_data_frame = pd.concat(data_frames, ignore_index=True)\n",
    "    final_data_frame.index = np.arange(1, len(final_data_frame) + 1)\n",
    "    #print(final_data_frame)\n",
    "    \n",
    "    gff_final_data_frame = pd.concat(gff_data_frames, ignore_index = True)\n",
    "    gff_final_data_frame.index = np.arange(1, len(gff_final_data_frame) + 1)\n",
    "    print(gff_final_data_frame)\n",
    "    \n",
    "    #save_to_file(final_data_frame, \"przyciete_introny.tsv\")\n",
    "    #save_to_gff_file(gff_final_data_frame, \"gff_przyciete_introny.tsv\")\n",
    "    print(\"Koniec funkcji\")\n",
    "\n",
    "\n",
    "\n",
    "def percentage_of_advancement(directory):\n",
    "    count = 0\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".fasta\"):\n",
    "            count += 1\n",
    "    return(count)\n",
    "\n",
    "\n",
    "def extracting_strands_from_alignment(alignment): #that function describe what strand is transcript strand and genomic strand - in our files, transcript strand has longer ID.\n",
    "    #print(f\"Alignment: {alignment[0].id}, funkcja: extracting_strands_from_alignment, przeszlo\")\n",
    "    if len(alignment[0].id) >= len(alignment[1].id):\n",
    "        \n",
    "        seq1 = alignment[0].seq\n",
    "        seq2 = alignment[1].seq\n",
    "        seq1_is_transcript = True\n",
    "    else:\n",
    "        seq1 = alignment[1].seq\n",
    "        seq2 = alignment[0].seq    \n",
    "        seq1_is_transcript = False\n",
    "    #print(f\"\\n Just run function: extracting_strands_from_alignment\")\n",
    "    return seq1, seq2\n",
    "    \n",
    "\n",
    "def finding_gap_index(sequence, acceptable_gap_length): #finding index of first gap in each sequence\n",
    "    #print(f\"Alignment: {alignment[0].id}, funkcja: finding_gap_index, przeszlo\")\n",
    "    return sequence.find(\"-\" * acceptable_gap_length) #-1 is output when anything was found\n",
    "\n",
    "\n",
    "def reversed_finding_gap_index(sequence, acceptable_gap_length): #finding index of first gap in each sequence for counting the end of intron\n",
    "    #print(f\"Alignment: {alignment[0].id}, funkcja: reversed_finding_gap_index, przeszlo\")\n",
    "    return sequence.rfind(\"-\" * acceptable_gap_length) + acceptable_gap_length #now we have to add length of gap to index, because python starts counting from 0 nt, and we just change direction of counting.\n",
    "\n",
    "def setting_distance_between_first_nt_and_gap(is_it_exon, seq1, first_gap_position_seq1, first_gap_position_seq2, last_gap_position_seq1, last_gap_position_seq2): #it means lenght of exon\n",
    "    #print(f\"Alignment: {alignment[0].id}, funkcja: setting_distance_between_first_nt_and_gap, przeszlo\")\n",
    "    if is_it_exon == True:\n",
    "        if first_gap_position_seq2 < 0: #when in second strand there are no gaps - it means, second strand is correctly prepared. <0 because find() function gives -1 result when not find\n",
    "            distance_between_first_nt_and_gap = first_gap_position_seq1 #more important is seq2 because it is genomic sequence, ~reference sequence\n",
    "        elif first_gap_position_seq1 < 0:\n",
    "            distance_between_first_nt_and_gap = first_gap_position_seq2\n",
    "        else:\n",
    "            distance_between_first_nt_and_gap = min(first_gap_position_seq1, first_gap_position_seq2)\n",
    "        return distance_between_first_nt_and_gap\n",
    "\n",
    "    elif is_it_exon == False:\n",
    "        if last_gap_position_seq2 < 0: #it means, if there is no gaps in second sequention, gap position is gap position in seq1. Additional, rfind() function return \"-1\" if it won't find any gaps in seq\n",
    "            distance_between_first_nt_and_gap = (len(seq1) - last_gap_position_seq1) -1\n",
    "            #print(\"pierwszy\", distance_between_first_nt_and_gap) #checkpoint\n",
    "        else:\n",
    "            distance_between_first_nt_and_gap = (len(seq1) - max(last_gap_position_seq1, last_gap_position_seq2))\n",
    "        return distance_between_first_nt_and_gap\n",
    "            #print(\"drugi\", distance_between_first_nt_and_gap) #checkpoint\n",
    "\n",
    "        \n",
    "def describing_class_of_exon(percent_of_homology, last_nt_exon_index, min_length_aligned_sequence, class_of_exon): #class of exon depends of their homology\n",
    "    #print(f\"Alignment: {alignment[0].id}, funkcja: describing_class_of_exon, przeszlo\")def \n",
    "    if percent_of_homology >= 0.9 and last_nt_exon_index >= min_length_aligned_sequence:\n",
    "        class_of_exon.append(\"1\")\n",
    "    elif percent_of_homology < 0.9 and percent_of_homology > 0 and last_nt_exon_index < min_length_aligned_sequence:\n",
    "        class_of_exon.append(\"2\")\n",
    "    else:\n",
    "        class_of_exon.append(\"3\")\n",
    "\n",
    "\n",
    "def exons_indices(is_it_exon, max_genomic_seq, seq2, last_nt_exon_index, first_nt_position, last_nt_position):\n",
    "    #print(f\"Alignment: {alignment[0].id}, funkcja: exons_indices, przeszlo\")\n",
    "    if is_it_exon:\n",
    "        first_nt_index_of_exon = max_genomic_seq.find(str(seq2[:last_nt_exon_index]).replace(\"-\", \"\"))\n",
    "        if first_nt_index_of_exon == -1:\n",
    "            first_nt_position.append(0)\n",
    "            last_nt_position.append(0)\n",
    "            #print(f\"That exon: {seq2[:last_nt_exon_index].replace('-', '')} comes from genomic sequence and cannot be found in file_before_MAFFT.\")\n",
    "        else:\n",
    "            first_nt_position.append(first_nt_index_of_exon + 1)\n",
    "            last_nt_position.append(first_nt_index_of_exon + len(seq2[:last_nt_exon_index]))\n",
    "            \n",
    "#### od tego momentu zacznij sprawdzania funkcji \n",
    "def introns_indices(is_it_exon, max_genomic_seq, seq2, last_nt_intron_index, first_nt_position, last_nt_position):\n",
    "    #print(f\"Alignment: {alignment[0].id}, funkcja: introns_indices, przeszlo\")\n",
    "    if is_it_exon: \n",
    "        first_nt_index_of_intron = max_genomic_seq.find(str(seq2[:last_nt_intron_index]))\n",
    "        if first_nt_index_of_intron == -1:\n",
    "            first_nt_position.append(0)\n",
    "            last_nt_position.append(0)\n",
    "        else:\n",
    "            first_nt_position.append(first_nt_index_of_intron + 1)\n",
    "            last_nt_position.append(first_nt_index_of_intron + len(seq2[:last_nt_intron_index]))\n",
    "\n",
    "\n",
    "def extending_source_data_frame(alignment, source):\n",
    "    #print(f\"Alignment: {alignment[0].id}, funkcja: extending_source_data_frame, przeszlo\")\n",
    "    keywords = [\"TRINITY\", \"BACKBONE\", \"SCAFFOLD\"]\n",
    "    found = False\n",
    "    for key in keywords:\n",
    "        if str(alignment[0]).lower().find(key.lower()) != -1:\n",
    "            source.append(key)\n",
    "            found = True\n",
    "            break\n",
    "            \n",
    "    if not found:\n",
    "        source.append(None) #none means unknown\n",
    "\n",
    "\n",
    "def extending_strand_data_frame(alignment, strand): \n",
    "    #print(f\"Alignment: {alignment[0].id}, funkcja: extending_strand_data_frame, przeszlo\")\n",
    "    if str(alignment[0]).find(\"SL+\") != -1:\n",
    "        strand.append(\"+\")\n",
    "    elif str(alignment[0]).find(\"SL-\") != -1:\n",
    "        strand.append(\"-\")\n",
    "    else:\n",
    "        strand.append(None)\n",
    "\n",
    "\n",
    "def extending_start_and_end_data_frame(is_it_exon, seq2, seq2_DT, start, end, distance_between_first_nt_and_gap, last_nt_exon_index): #index of exons's/intron's start\n",
    "    #print(f\"Alignment: {alignment[0].id}, funkcja: extending_start_and_end_data_frame, przeszlo\")\n",
    "    if is_it_exon:\n",
    "        start.append(seq2_DT.find(seq2[:distance_between_first_nt_and_gap])+1)\n",
    "        end.append(seq2_DT.find(seq2[:distance_between_first_nt_and_gap]) + last_nt_exon_index)\n",
    "    if not is_it_exon:\n",
    "        start.append(seq2_DT.find(seq2[:distance_between_first_nt_and_gap])+1)\n",
    "        end.append(seq2_DT.find(seq2[:distance_between_first_nt_and_gap]) + last_nt_intron_index)\n",
    "\n",
    "\n",
    "def save_to_file(final_data_frame, filename):\n",
    "    #print(f\"Alignment: {alignment[0].id}, funkcja: save_to_file, przeszlo\")\n",
    "    if os.path.isfile(filename):\n",
    "        user_input = input(\"TSV file already exists. Do you want overwrite? y/n: \")\n",
    "        if user_input == \"n\":\n",
    "            base_name, ext = os.path.splitext(filename)\n",
    "            i = 1\n",
    "            while os.path.isfile(f\"{base_name}_{i}{ext}\"):\n",
    "                i += 1\n",
    "            filename = f\"{base_name}_{i}{ext}\"\n",
    "            final_data_frame.to_csv(filename, sep = \"\\t\")\n",
    "            \n",
    "        elif user_input == \"y\":\n",
    "            final_data_frame.to_csv(filename, sep = \"\\t\")\n",
    "        else:\n",
    "            print(\"Clarify your answer. Nothing has done.\")\n",
    "            \n",
    "    else:\n",
    "        final_data_frame.to_csv(filename, sep = \"\\t\")\n",
    "\n",
    "def save_to_gff_file(gff_final_data_frame, filename):\n",
    "    #print(f\"Alignment: {alignment[0].id}, funkcja: save_to_gff_file, przeszlo\")\n",
    "    if os.path.isfile(filename):\n",
    "        user_input = input(\"GFF file already exists. Do you want overwrite? y/n: \")\n",
    "        if user_input == \"n\":\n",
    "            base_name, ext = os.path.splitext(filename)\n",
    "            i = 1\n",
    "            while os.path.isfile(f\"{base_name}_{i}{ext}\"):\n",
    "                i += 1\n",
    "            filename = f\"{base_name}_{i}{ext}\"\n",
    "            gff_final_data_frame.to_csv(filename, sep = \"\\t\")\n",
    "            \n",
    "        elif user_input == \"y\":\n",
    "            gff_final_data_frame.to_csv(filename, sep = \"\\t\")\n",
    "        else:\n",
    "            print(\"Clarify your answer. Nothing has done.\")\n",
    "            \n",
    "    else:\n",
    "        gff_final_data_frame.to_csv(filename, sep = \"\\t\")\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    cutting_scrap(path_to_file_before_MAFFT, path_to_file_after_MAFFT, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9603c0b7-3d7a-4dcc-89e1-2c59f3db2f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27883026-921f-4c58-b960-f4118789cf43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
